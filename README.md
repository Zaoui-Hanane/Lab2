
# NLP Rule Based, Regex, and Word Embedding Lab
## Objective
The main purpose behind this lab is to gain familiarity with NLP rule-based techniques, regular expressions (Regex), and word embedding methodologies.

## Part 1: Rule Based NLP and Regex
In this part, we use regular expressions in Python to generate a bill from a given text provided by the user. The use case involves extracting product details, quantities, unit prices, and calculating total prices.
## Part 2: Word Embedding
In this part, we explore various word embedding techniques on the dataset collected during Part 1.

One Hot Encoding, Bag of Words, TF-IDF Techniques: We apply these traditional vectorization techniques on the dataset.
Word2Vec Approach (Skip Gram, CBOW): We utilize Word2Vec to generate word embeddings, exploring both Skip Gram and Continuous Bag of Words (CBOW) architectures.
GloVe and FastText Approaches: We apply GloVe and FastText algorithms to create word embeddings on the same dataset.
Plotting Vectorized Vectors with t-SNE Algorithm: We use t-distributed Stochastic Neighbor Embedding (t-SNE) to visualize the encoded/vectorized word vectors. The aim is to evaluate the performance of each embedding approach and draw general conclusions based on the distribution and relationships between words in the plot.
# Conclusion
During this lab, I delved into the practical implementation of rule-based NLP techniques employing Regex and delved into a variety of word embedding methods. I discovered that while rule-based NLP can excel in targeted tasks such as bill generation, word embedding techniques offer robust means to capture semantic relationships and contextual nuances within textual data. This hands-on experience provided valuable insights into the array of methods accessible for text data processing and analysis in NLP applications.
